from django.shortcuts import render
from django.http import JsonResponse
from rest_framework.decorators import api_view
from rest_framework.response import Response
from rest_framework import status
import requests
import json
import logging

logger = logging.getLogger(__name__)


@api_view(['GET'])
def text_ai_detection_view(request):
    """
    Basic info endpoint for text AI detection service
    """
    return Response({
        'service': 'Text AI Detection',
        'description': 'Detects AI-generated text content',
        'endpoints': {
            'analyze': '/text-ai-detection/analyze/ (POST)'
        }
    })


@api_view(['POST'])
def analyze_text(request):
    """
    Analyze text for AI generation detection using Hack Club AI API
    """
    text = request.data.get('text', '')
    
    if not text:
        return Response(
            {'error': 'Text content is required'}, 
            status=status.HTTP_400_BAD_REQUEST
        )
    
    try:
        # Create comprehensive prompt for both AI detection and fake news analysis
        analysis_prompt = f"""
Analyze the following text for two things:
1. Determine if it was likely generated by AI or written by a human
2. Assess if the content contains misinformation, fake news, or misleading claims

Provide your analysis in this exact JSON format:
{{
    "ai_likelihood_percentage": <number between 0-100>,
    "ai_reasoning": "<brief explanation of AI detection analysis>",
    "ai_confidence": "<high/medium/low>",
    "fake_news_likelihood_percentage": <number between 0-100>,
    "fake_news_reasoning": "<brief explanation of fact-checking and credibility analysis>",
    "fake_news_confidence": "<high/medium/low>",
    "credibility_score": <number between 0-100>
}}

Text to analyze:
"{text}"
"""
        
        # Make request to Hack Club AI API
        api_url = "https://ai.hackclub.com/chat/completions"
        headers = {
            "Content-Type": "application/json"
        }
        
        payload = {
            "messages": [
                {
                    "role": "user", 
                    "content": analysis_prompt
                }
            ]
        }
        
        response = requests.post(api_url, headers=headers, json=payload, timeout=30)
        response.raise_for_status()
        
        ai_response = response.json()
        ai_content = ai_response.get('choices', [{}])[0].get('message', {}).get('content', '')
        
        # Try to parse the AI response as JSON
        try:
            # Extract JSON from the response if it's wrapped in markdown or other text
            import re
            json_match = re.search(r'\{[^}]*"ai_likelihood_percentage"[^}]*"credibility_score"[^}]*\}', ai_content)
            if json_match:
                analysis_data = json.loads(json_match.group())
            else:
                # Fallback parsing if JSON format is not found
                raise ValueError("No valid JSON found in response")
        except (json.JSONDecodeError, ValueError):
            # Fallback: parse manually or provide default analysis
            logger.warning(f"Could not parse AI response as JSON: {ai_content}")
            
            # Try to extract percentages from text response
            ai_percentage_match = re.search(r'AI.*?(\d+)%', ai_content, re.IGNORECASE)
            fake_percentage_match = re.search(r'fake.*?(\d+)%', ai_content, re.IGNORECASE)
            
            ai_percentage = int(ai_percentage_match.group(1)) if ai_percentage_match else 50
            fake_percentage = int(fake_percentage_match.group(1)) if fake_percentage_match else 30
            
            analysis_data = {
                "ai_likelihood_percentage": ai_percentage,
                "ai_reasoning": ai_content[:150] + "..." if len(ai_content) > 150 else ai_content,
                "ai_confidence": "medium",
                "fake_news_likelihood_percentage": fake_percentage,
                "fake_news_reasoning": "Analysis based on content patterns and factual consistency",
                "fake_news_confidence": "medium",
                "credibility_score": 100 - fake_percentage
            }
        
        # Format the comprehensive response
        result = {
            'text': text,
            # AI Detection Results
            'ai_likelihood_percentage': analysis_data.get('ai_likelihood_percentage', 50),
            'ai_reasoning': analysis_data.get('ai_reasoning', 'AI detection analysis completed'),
            'ai_confidence': analysis_data.get('ai_confidence', 'medium'),
            'is_ai_generated': analysis_data.get('ai_likelihood_percentage', 50) > 50,
            # Fake News Detection Results
            'fake_news_likelihood_percentage': analysis_data.get('fake_news_likelihood_percentage', 30),
            'fake_news_reasoning': analysis_data.get('fake_news_reasoning', 'Fact-checking analysis completed'),
            'fake_news_confidence': analysis_data.get('fake_news_confidence', 'medium'),
            'is_fake_news': analysis_data.get('fake_news_likelihood_percentage', 30) > 50,
            'credibility_score': analysis_data.get('credibility_score', 70),
            # Metadata
            'model_used': 'Hack Club AI Service',
            'timestamp': request.META.get('HTTP_DATE', '')
        }
        
        return Response(result)
        
    except requests.exceptions.RequestException as e:
        logger.error(f"Error calling Hack Club AI API: {str(e)}")
        return Response(
            {
                'error': 'Failed to analyze text - API service unavailable',
                'details': str(e)
            }, 
            status=status.HTTP_503_SERVICE_UNAVAILABLE
        )
    except Exception as e:
        logger.error(f"Unexpected error in text analysis: {str(e)}")
        return Response(
            {
                'error': 'Internal server error during text analysis',
                'details': str(e)
            }, 
            status=status.HTTP_500_INTERNAL_SERVER_ERROR
        )
